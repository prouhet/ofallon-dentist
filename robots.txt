User-agent: *
Allow: /

# Sitemap locations (add multiple if you have them)
Sitemap: https://ofallondentists.com/sitemap.xml
Sitemap: https://ofallondentists.com/sitemap-images.xml

# Major search engines - prioritize crawling
User-agent: Googlebot
Allow: /
Crawl-delay: 0

User-agent: Bingbot
Allow: /
Crawl-delay: 0

User-agent: Slurp
Allow: /

User-agent: DuckDuckBot
Allow: /

User-agent: YandexBot
Allow: /

User-agent: Baiduspider
Allow: /

# AI crawlers for LLMO (Large Language Model Optimization)
User-agent: GPTBot
Allow: /

User-agent: Google-Extended
Allow: /

User-agent: CCBot
Allow: /

User-agent: ChatGPT-User
Allow: /

User-agent: Claude-Web
Allow: /

User-agent: ClaudeBot
Allow: /

User-agent: anthropic-ai
Allow: /

User-agent: PerplexityBot
Allow: /

User-agent: YouBot
Allow: /

User-agent: Meta-ExternalAgent
Allow: /

# Social media crawlers for better social sharing
User-agent: facebookexternalhit
Allow: /

User-agent: Twitterbot
Allow: /

User-agent: LinkedInBot
Allow: /

User-agent: WhatsApp
Allow: /

User-agent: TelegramBot
Allow: /

# Local business and review crawlers
User-agent: AppleBot
Allow: /

# Academic and research crawlers
User-agent: ia_archiver
Allow: /

# Control aggressive SEO crawlers (allow but with delay)
User-agent: AhrefsBot
Allow: /
Crawl-delay: 10

User-agent: SemrushBot
Allow: /
Crawl-delay: 10

User-agent: MJ12bot
Allow: /
Crawl-delay: 10

User-agent: DotBot
Crawl-delay: 10

User-agent: SiteAuditBot
Crawl-delay: 10

# Block problematic or spam bots
User-agent: SentiBot
Disallow: /

User-agent: AhrefsBot
Disallow: /

User-agent: SemrushBot  
Disallow: /

User-agent: MJ12bot
Disallow: /

User-agent: DotBot
Disallow: /

User-agent: BLEXBot
Disallow: /

User-agent: DataForSeoBot
Disallow: /

User-agent: PetalBot
Disallow: /

# Block unwanted content scraping
User-agent: *
Disallow: /admin/
Disallow: /private/
Disallow: /*.json$
Disallow: /*?print=
Disallow: /*&print=
